s maria_dev I created the following directory in hdfs structure
hdfs dfs -mkdir hdpcd
this will create the following /user/maria_dev/hdpcd (hdpcd is created under the user/maria_dev automatically
without specifying /user/maria_dev

copy file to hdpcd
hdfs dfs -put hadoopexam6.txt hdpcd/

# because the user maria_dev is already configured as a hadoop user and has its own directory as mentioned above
# the command below will work just fine if we use this path "hdpcd/hadoopexam6_nohead.txt", no need to preceed with
# hdfs: and /user/maria_dev
rdd1 = sc.textFile("hdfs:/user/maria_dev/hdpcd/hadoopexam6_nohead.txt")
rdd2 = rdd1.map(lambda x : x.split(","))
rdd3 = rdd2.map(lambda x : float(x[1])*(1 + float(x[2])/100)) # this just returns the values
rdd4 = rdd2.map(lambda x :  (x[0],float(x[1])*(1 + float(x[2])/100))) # return pair RDD
>>> rdd4.first()
(u'Hadoop', 3334.9999999999995)


In Scala:
val rdd1 = sc.textFile("hdfs:/user/maria_dev/hdpcd/hadoopexam6_nohead.txt")
val rdd2 = rdd1.map( x => x.split(","))
val rdd3 = rdd2.map( x => (x(0), x(1).toDouble*(1.0+x(2).toDouble/100.0))  )
scala> rdd3.first()
res3: (String, Double) = (Hadoop,3334.9999999999995)

#---------------- Scala cleaner (flattended solution ) --------------- 
val rdd1 = sc.textFile("hdfs:/user/maria_dev/hdpcd/hadoopexam6_nohead.txt")
val rdd3 = rdd1.map( x => (x, (x.split(",")(1).toDouble*(1.0+x.split(",")(2).toDouble/100.0)))  )
rdd3.first()
res0: (String, Double) = (Hadoop,2900,15,3334.9999999999995)
rdd3.saveAsTextFile("hdpcd/hadoopexam6_sol.txt")


